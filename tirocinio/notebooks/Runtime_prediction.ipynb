{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3dd140-9cae-49e2-b1b7-d5f54126b3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Installazione librerie\n",
    "# ============================================================\n",
    "\n",
    "# %pip install psycopg2_binary\n",
    "# %pip install ipython-sql\n",
    "# %pip install stats\n",
    "# %pip install nltk\n",
    "# import nltk\n",
    "# nltk.download('stopwords')\n",
    "# %pip install cudf-cu11 dask-cudf-cu11 --extra-index-url=https://pypi.ngc.nvidia.com\n",
    "# %pip install cuml-cu11 --extra-index-url=https://pypi.ngc.nvidia.com\n",
    "# %pip install numba conda update numba\n",
    "# %pip install hdbscan\n",
    "# %pip install xgboost\n",
    "# %pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5518534-b64f-42cd-984b-00d243f1cc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85e6107c-168a-428a-bd6d-8aa87a263149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Notebook setup\n",
    "# ============================================================\n",
    "\n",
    "%load_ext sql\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "random_state = 42\n",
    "figsize = (15,12)\n",
    "\n",
    "import os, json\n",
    "from sqlalchemy import create_engine\n",
    "from ast import literal_eval\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "from util import query, util\n",
    "\n",
    "# librerie grafiche\n",
    "import seaborn as sns\n",
    "sns.set_theme(palette=\"Set1\")\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "681df063-5b5a-4227-b4d7-a9ef5704427e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Connessione Postgres DB\n",
    "# ============================================================\n",
    "\n",
    "connstring = 'postgresql://accguy:accguy@192.168.1.17/htm'\n",
    "engine = create_engine(connstring)\n",
    "%sql postgresql://accguy:accguy@192.168.1.17/htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6469fd55-8dad-461e-ab55-289eb8227ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%sql\n",
    "# SELECT * from pg_stat_activity;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab4240ba-7a7f-40d3-a5ff-f94175396509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%sql\n",
    "# SELECT pg_cancel_backend(410855)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd6503f-8985-41bb-877b-8774d50eb847",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Runtime Prediction\n",
    "\n",
    "Determinare la \"categoria\" di job dal comportamento del job nella sua prima ora di \"vita\".\n",
    "- Basta un'ora per determinare la categoria del job?\n",
    "- Il fatto che il job fallisca è rilevante?\n",
    "- Sarà importante valutare il comportamento del job in relazione allo stato delle macchine\n",
    "- Che subset prendiamo? Come varia il comportamento di un job nella sua prima ora nelle diverse settimane e mesi da Settembre 2021 a Dicembre 2021?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d9325ded-84f5-4f7c-b3e5-0d2d04ffaf68",
   "metadata": {},
   "source": [
    "* BINNING WALL TIME\n",
    "* ONE-HOT ENCODING QUEUE\n",
    "* HOW MUCH TIME FOR DEFINE JOB CATEGORY?\n",
    "\n",
    "* approccio supervised:\n",
    "    * classificazione\n",
    "* approccio unsupervised:\n",
    "    * clustering + recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6425c34-1a87-4bfd-982b-97cfa1b132ab",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Preprocessing\n",
    "\n",
    "xt <= 180\n",
    "\n",
    "* preprocessing panel data:\n",
    "    * job, timestep, ram, swap, disk\n",
    "    * job, ram_1, swap_1, disk_1, ... , ram_n, swap_n, disk_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef76d04-9f30-491d-a80c-8b237cb38e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOWNLOAD\n"
     ]
    }
   ],
   "source": [
    "PATH = '../data/out.zip'\n",
    "TIME_SERIES_COLUMNS = ['ram', 'img', 'disk']\n",
    "TIME_STEP_COLUMN = 't'\n",
    "START_DATE, END_DATE = '2021-09-01', '2021-09-30'\n",
    "MIN_RUNTIME = 7200\n",
    "\n",
    "compression_opts = dict(method='zip', archive_name='out.csv')\n",
    "\n",
    "if os.path.exists(PATH):\n",
    "    print(\"CACHE\")\n",
    "    df = pd.read_csv(PATH)\n",
    "    for COL in TIME_SERIES_COLUMNS:\n",
    "        df[COL] = df[COL].apply(lambda x: literal_eval(x))\n",
    "    df.set_index(pd.to_datetime(df['mint'], unit='s'), inplace=True)\n",
    "else:\n",
    "    print(\"DOWNLOAD\")\n",
    "    df = pd.read_sql(query.jobs_from_date_to_date, engine, params=([START_DATE, MIN_RUNTIME, END_DATE, MIN_RUNTIME, START_DATE, END_DATE, MIN_RUNTIME]))\n",
    "    df.to_csv(PATH, index=False, compression=compression_opts)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd09f32-5b98-4060-af71-7d52bfffc401",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_time_series(df: pd.DataFrame, columns, sliceTime = slice(None, None)):\n",
    "    return pd.concat([df[sliceTime][col].apply(lambda x: np.mean(x)) for col in columns], axis=1)\n",
    "\n",
    "aggr_df = aggregate_time_series(df, TIME_SERIES_COLUMNS, slice('2021-09-01', '2021-09-02'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8ccc39-f160-4906-a5a0-879660161904",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggr_df['runtime'] = df[slice('2021-09-01', '2021-09-02')].maxt - df[slice('2021-09-01', '2021-09-02')].mint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20b9e8d-512b-41fe-94fe-ba58947fcf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_time_series(df: pd.DataFrame, columns, time_column, sliceTime = slice(None, None)):\n",
    "    new_df = df[sliceTime].explode(columns)\n",
    "    new_df[time_column] = (np.arange(0, len(new_df)) % 20)\n",
    "    return new_df.sort_values(by=time_column).reset_index(drop=True)\n",
    "\n",
    "transformed_df = transform_time_series(df, TIME_SERIES_COLUMNS, TIME_STEP_COLUMN, slice('2021-09-01', '2021-09-02'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38e2d9d-5bb1-47df-a280-2d4eb50abcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df['runtime'] = transformed_df['maxt'] - transformed_df['mint']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f0e49e-b449-4006-80d1-fb7b49a7e7ec",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77aaea11-4a4e-492e-9a28-d97c36439083",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "select *\n",
    "from htjob\n",
    "limit 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d79b172-2ced-4bab-96be-d3b820a2957f",
   "metadata": {},
   "source": [
    "## Valutazione modelli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a33e44c-1f86-4c5c-ab1a-3e169e4df03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66a123c-5d5e-4560-9f92-b4a54821ef6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "LABELS = [\"short\", \"medium\", \"long\"]\n",
    "\n",
    "def bin_job_runtime(vect_runtime: pd.Series, lower_bound = 6, upper_bound = 30):\n",
    "    return pd.cut(vect_runtime / 3600.0, bins = [-float(\"inf\"), lower_bound, upper_bound, len(vect_runtime)], right=False, labels=LABELS)\n",
    "\n",
    "def confidence_interval(N, acc, alpha=0.05, verbose=False):\n",
    "    if verbose:\n",
    "        print(f\"\\n *** Calcolo intervallo di confidenza per alpha: {alpha}, N: {N} ***\\n\")\n",
    "            \n",
    "    Z = st.norm.ppf(1-alpha/2)\n",
    "    denom = 2*(N+Z**2)\n",
    "    p_min = (2 * N * acc + Z**2 - Z * (Z**2 + 4 * N * acc -4 * N * acc**2)**.5)/denom\n",
    "    p_max = (2 * N * acc + Z**2 + Z * (Z**2 + 4 * N * acc -4 * N * acc**2)**.5)/denom\n",
    "    \n",
    "    return p_min, p_max\n",
    "\n",
    "def eval_model(X, y, model, alpha=0.05, verbose=False):\n",
    "    binarizer = LabelEncoder()\n",
    "    y_true = binarizer.fit_transform(bin_job_runtime(y))\n",
    "    y_pred = binarizer.transform(bin_job_runtime(model.predict(X)))\n",
    "    \n",
    "    labels = LABELS\n",
    "    metrics = [\"precision\", \"recall\", \"f1_measure\"]\n",
    "    \n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average=None)\n",
    "    recall = recall_score(y_true, y_pred, average=None)\n",
    "    f1_measure = f1_score(y_true, y_pred, average=None)\n",
    "    all_classes = pd.Series([precision.mean(), recall.mean(), f1_measure.mean()],  index=metrics)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"\\n*** Confusion matrix ***\\n\")\n",
    "        cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "        sns.heatmap(cf_matrix, annot=True, cmap = \"Blues\", fmt=\"d\", xticklabels=labels, yticklabels=labels)\n",
    "        plt.title('Confusion matrix')\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label')\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"\\n*** Precision, Recall, F1-measure per classe e media ***\\n\")\n",
    "        model_stats = pd.concat(\n",
    "            [pd.DataFrame([precision, recall, f1_measure], index=metrics), all_classes], axis=1)\n",
    "        model_stats.columns = labels + [\"all\"]\n",
    "        print(model_stats)\n",
    "\n",
    "        print(f\"\\n*** Calcolo intervallo di confidenza con Confidenza={1-alpha} con N={X.shape[0]} per accuracy e f1-measure ***\\n\")\n",
    "        print(f\"accuracy: ({accuracy}), intervallo confidenza: {confidence_interval(X.shape[0], accuracy, alpha)}\")\n",
    "        print(f\"f1-measure: ({f1_measure.mean()}), intervallo confidenza: {confidence_interval(X.shape[0], f1_measure.mean(), alpha)}\")\n",
    "\n",
    "    return (accuracy, f1_measure.mean())\n",
    "\n",
    "def eval_difference_two_model(acc1, acc2, N1, N2, alpha=0.05, confidence_level=False):\n",
    "    print(f\"\\n*** Valutazione statistica differenza tra modello 1 e modello 2 ***\")\n",
    "    print(f\"(acc: {acc1}, N: {N1}) (acc: {acc2}, N: {N2})\\n\")\n",
    "    Z = st.norm.ppf(1-alpha/2)\n",
    "    e1 = 1 - acc1; e2 = 1 - acc2\n",
    "    d= abs(e2-e1)\n",
    "    var_d = (e1*(1-e1))/N1 + (e2*(1-e2))/N2\n",
    "    d_min = d - Z * var_d**0.5\n",
    "    d_max = d + Z * var_d**0.5\n",
    "    \n",
    "    if confidence_level:\n",
    "        print(f\"\\n*** Valutazione soglia confidenza che rende significativa la differenza tra i due modelli ***\")\n",
    "        print(f\"a: {round(st.norm.sf(d/var_d**0.5) * 2, 2)}\\n\")\n",
    "    \n",
    "    return d_min, d_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524a286d-c912-41ad-abdc-c55eab6ada85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, y = transformed_df[TIME_SERIES_COLUMNS + [TIME_STEP_COLUMN]], transformed_df['runtime']\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=random_state)\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('time_series', StandardScaler(), TIME_SERIES_COLUMNS),\n",
    "    # ('time_step', OneHotEncoder(sparse=False, handle_unknown='ignore'), [TIME_STEP_COLUMN])\n",
    "], remainder=\"drop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699789ed-c0aa-4fc7-9983-de435d40f526",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = aggr_df[TIME_SERIES_COLUMNS], aggr_df['runtime']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136d6178-3bc6-4af1-a7f5-cfca9ef4bbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_model = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"forest\", RandomForestRegressor())\n",
    "])\n",
    "\n",
    "xgboost_model = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"xgboost\", XGBRegressor(tree_method='gpu_hist'))\n",
    "])\n",
    "\n",
    "forest_model.fit(X_test, y_test)\n",
    "xgboost_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996c12ae-eef5-4d86-88fe-8372f11bfd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model(X_test, y_test, forest_model, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdf1ab1-e8e7-47bf-9424-01776f8c58ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model(X_test, y_test, xgboost_model, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761191a9-8cfd-4d17-918f-9709f547c0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "online_model = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"feature_map_nystroem\", Nystroem(gamma=.8, random_state=random_state, n_components=300)),\n",
    "    (\"sgd\", SGDRegressor(warm_start=True, shuffle=False))\n",
    "])\n",
    "\n",
    "def pipeline_partial_fit(pipeline, X, y):\n",
    "    data_preprocessed = pipeline.named_steps['preprocessor'].fit_transform(X)\n",
    "    data_transformed = pipeline.named_steps['feature_map_nystroem'].fit_transform(data_preprocessed)\n",
    "    pipeline.named_steps['sgd'].partial_fit(data_transformed, y)\n",
    "    \n",
    "pipeline_partial_fit(online_model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11100b84-4225-4469-a460-63e43969bcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f7923c-ccbf-42d3-9c48-2c15b127193d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_model.named_steps['xgboost'].feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f2c847-ddb2-4163-b9d2-e353cff348cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ccc270-982f-4533-8c13-127401ff5d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_partial_fit(online_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393a64e7-b490-4730-8033-9b173b21f497",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = aggregate_time_series(df[slice('2021-09-03', '2021-09-04')], TIME_SERIES_COLUMNS)\n",
    "y_val = df[slice('2021-09-03', '2021-09-04')].maxt - df[slice('2021-09-03', '2021-09-04')].mint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfb7a77-b9d9-4b9e-8e1d-0db58e1af9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_model.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b93742-4082-4ba1-864d-cc721e16cd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_model.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0523d730-d431-4dc0-832d-23f6356f4067",
   "metadata": {},
   "outputs": [],
   "source": [
    "online_model.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efcac3c-04aa-46f3-8b49-5ccd54007617",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "select *\n",
    "from htjob jd INNER JOIN hm m ON\n",
    "    jd.exechosts = m.hn\n",
    "WHERE jd.eventtimeepoch BETWEEN extract(epoch from m.ts)AND extract(epoch from m.ts)\n",
    "limit 100;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f31f3d4-23eb-4b06-83a5-ad7991409eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "select *\n",
    "from hj j INNER JOIN hm m ON j.hn = m.hn AND\n",
    "    j.ts BETWEEN extract(epoch from m.ts) - 180 AND extract(epoch from m.ts) + 180\n",
    "limit 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1367fab1-a3d0-447f-bcd3-8a03a0b19101",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pd.Series(forest_model.predict(X_val), index=X_val.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e097c4d8-c3db-4aab-90b8-c4b82e8710f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(forest_model.named_steps[\"forest\"].feature_importances_, index=TIME_SERIES_COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55804696-28d0-4b15-af65-3feb2ecd78fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([X_val, y_val, preds], axis=1)[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c437f29-a731-481a-bd04-0f95f0055d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_model.predict(aggregate_time_series(df[slice('2021-09-03', '2021-09-04')], TIME_SERIES_COLUMNS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74111bf5-42bd-43c7-a9fa-9b0eaf14ce83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
