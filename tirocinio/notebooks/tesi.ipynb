{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42bbef2f-b958-4040-aead-f8aac09d9311",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load moduli e dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8b28d9c-f677-4b51-b017-f61b0de7775b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============== #\n",
    "# Notebook setup  #\n",
    "# =============== #\n",
    "%load_ext sql\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "random_state = 42\n",
    "figsize = (15,12)\n",
    "\n",
    "import os, json\n",
    "import ast\n",
    "from sqlalchemy import create_engine\n",
    "from ast import literal_eval\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "from util import query, util\n",
    "from joblib import dump\n",
    "\n",
    "# librerie grafiche\n",
    "import seaborn as sns\n",
    "sns.set_theme(palette=\"Set1\")\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f450745c-352b-4087-9e70-63a916952e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================== #\n",
    "# Connessione Postgres DB  #\n",
    "# ======================== #\n",
    "\n",
    "connstring = 'postgresql://accguy:accguy@192.168.1.17/htmnew'\n",
    "engine = create_engine(connstring)\n",
    "%sql postgresql://accguy:accguy@192.168.1.17/htmnew"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6313482-d090-4d23-aed9-d9a4d6b42e4f",
   "metadata": {},
   "source": [
    "### Scaletta\n",
    "\n",
    "1) Training:\n",
    "- [ ] usare dataset marzo 2023\n",
    "- [ ] trasformazione dataset\n",
    "    - media mobile 15 min\n",
    "    - si/no padding\n",
    "- [ ] usare padding / casual\n",
    "- [ ] <i>undersample</i>: usare mix x% job falliti + (100-x)% x job non falliti (con algoritmi di classificazione)\n",
    "- [ ] <i>oversample: </i> o in alternativa generare dati sintentici\n",
    "- [ ] passare ad algoritmi di anomaly detection (es: isolation forest)\n",
    "\n",
    "2. preparare funzione/script che dato un job running (con la sua storia dalla nascita) lo classifica (files /tmp/mondir/done/running/*.gz)\n",
    "    - Es. valuta.py 8731007.0 --> 1 / 0\n",
    "    Assumendo che il job in questione sia running da almeno 2h o più\n",
    "        - lo stato dei job running è in una tabella postgres con indice ts (timestamp)\n",
    "        - la ricerca nella tabella è del tipo:\n",
    "        ```sql \n",
    "            select blabla from where jobid = '<jobid>' and ts > now() - X;\n",
    "        ```\n",
    "        X si può passare come argomento facoltativo allo script, con default a 3*86400 secondi\n",
    "3. automatizzare lo script dal punto 2. deve segnalare (anomaly detection) su job running che per lui sono \"rotti\"\n",
    "(dump in un file di jobid sospetti)\n",
    "4. ispezionare a mano il job e capire da \"umano\" se è effettivamente \"zombie/rotto\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9373812b-29de-4ee5-b12a-0394dbfb527e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../data/out2.parquet'\n",
    "TIME_SERIES_COLUMNS = ['ram', 'swap', 'disk']\n",
    "TIME_STEP_COLUMN = 't'\n",
    "START_DATE, END_DATE = '2023-03-14', '2023-03-25'\n",
    "MIN_RUNTIME = 3600\n",
    "\n",
    "def load_dataset(path):\n",
    "    if os.path.exists(path):\n",
    "        print(\"CACHE\")\n",
    "        df = pl.read_parquet(path)\n",
    "    else:\n",
    "        print(\"DOWNLOAD\")\n",
    "        df = pl.from_pandas(pd.read_sql(query.jobs_from_date_to_date, engine, params=([START_DATE, MIN_RUNTIME, END_DATE, MIN_RUNTIME, START_DATE, END_DATE, MIN_RUNTIME])))\n",
    "        df.write_parquet(path, compression='snappy')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7018b7-304b-4dc8-9dc3-aa1e02d69fe2",
   "metadata": {},
   "source": [
    "Dataset da 2023-03-13 a 2023-04-01, circa ~3 settimane:\n",
    "- hj\n",
    "- hj_recent (contiene ~ le ultime 24 ore)\n",
    "- htjob_recent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e6c63e-fe04-4b86-a80a-70097be34cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOWNLOAD\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = load_dataset(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f881f581-88ea-4762-aad2-96a72d2fbd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6215e35c-fbf6-41c1-a9c8-d988595b4ecd",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6398967a-4d0c-42e7-a1e7-2acc55f3baab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
