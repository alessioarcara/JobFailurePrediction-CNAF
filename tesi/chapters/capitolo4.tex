\label{chap:valutazioni}

%You can automate the ML production pipelines to retrain the models with new data, depending on your use case:
%
%On demand: Ad-hoc manual execution of the pipeline.
%On a schedule: New, labelled data is systematically available for the ML system on a daily, weekly, or monthly basis. The retraining frequency also depends on how frequently the data patterns change, and how expensive it is to retrain your models.
%On availability of new training data: New data isn't systematically available for the ML system and instead is available on an ad-hoc basis when new data is collected and made available in the source databases.
%On model performance degradation: The model is retrained when there is noticeable performance degradation.
%On significant changes in the data distributions (concept drift). It's hard to assess the complete performance of the online model, but you notice significant changes on the data distributions of the features that are used to perform the prediction. These changes suggest that your model has gone stale, and that needs to be retrained on fresh data.

\section{Valutazione delle performance}
\subsection{Metriche di valutazione}

% f2 score 

\subsection{Convalida incrociata}
\section{Confronto tra i modelli}


% at each iteration, equation requires a complete pass through the intere
% dataset in orde to compute the gradient. 

% batch learning an entire batch of data must be considered before weight are
% updated

%L'input √® rappresentato da un tensore 3D (batch size, time steps,
%features)
%To train the LSTM you use the typical Mini-batch training. Make sure
%you don't propagate the state for batch sample ùëñ to sample ùëñ+1 in
%order to treat them individually (in Keras you set the stateful flag
%to False)
% Essentially, the author is describing a means for forecasting sales
% with LSTM whereby the model is trained on a mini-batch (or subset) of
% one series, and then a new series is selected.

%This would have the advantage of essentially creating a unified series
%that takes the characteristics of all weather stations into account -
%which allows for maximum utilisation of the data, as well as allowing
%the network to learn patterns from all stations - not just one or a
%select few.



%Una rete neurale composta solo da strati di convoluzione √® considerata una
%``fully convolution networks'', per la classificazione, la feature map
%ddell'ultimo strato convoluzionale viene vettorizzato in uno strato denso
%seguito da uno strato logistic.

\section{Interpretazione dei risultati}
%Most machine learning systems operate in batch mode. They analyze a set of
%historical data and then develop a model that reflects the world as it was
%when the model was formed. But the world is dynamic, and the complex
%distributions that a model models are likely to be non-stationary and thus to
%change over time, leading to deteriorating model performance.


%Data trumps all. It's true that updating your learning algorithm or model
%architecture will let you learn different types of patterns, but if your data
%is bad, you will end up building functions that fit the wrong thing. The
%quality and size of the data set matters much more than which shiny algorithm
%you use.
