\label{chap:valutazioni}

%You can automate the ML production pipelines to retrain the models with new data, depending on your use case:
%
%On demand: Ad-hoc manual execution of the pipeline.
%On a schedule: New, labelled data is systematically available for the ML system on a daily, weekly, or monthly basis. The retraining frequency also depends on how frequently the data patterns change, and how expensive it is to retrain your models.
%On availability of new training data: New data isn't systematically available for the ML system and instead is available on an ad-hoc basis when new data is collected and made available in the source databases.
%On model performance degradation: The model is retrained when there is noticeable performance degradation.
%On significant changes in the data distributions (concept drift). It's hard to assess the complete performance of the online model, but you notice significant changes on the data distributions of the features that are used to perform the prediction. These changes suggest that your model has gone stale, and that needs to be retrained on fresh data.

\section{Confronto tra i modelli}
\section{Interpretazione dei risultati}
%Most machine learning systems operate in batch mode. They analyze a set of
%historical data and then develop a model that reflects the world as it was
%when the model was formed. But the world is dynamic, and the complex
%distributions that a model models are likely to be non-stationary and thus to
%change over time, leading to deteriorating model performance.


%Data trumps all. It's true that updating your learning algorithm or model
%architecture will let you learn different types of patterns, but if your data
%is bad, you will end up building functions that fit the wrong thing. The
%quality and size of the data set matters much more than which shiny algorithm
%you use.
