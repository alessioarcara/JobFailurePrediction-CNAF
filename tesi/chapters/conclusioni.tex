\label{chap:conclusione}

Questo studio ha esplorato il problema di prevedere il successo o il
fallimento dei job in una farm di calcolo mediante l'uso di tecniche di
Machine Learning e Deep Learning. Dalle analisi effettuate nel
capitolo~\ref{chap:analisi}, è stato identificato un particolare sottoinsieme
di job che falliscono, denominati zombie. Questi, benché smettano di
effettuare calcoli, non rilasciano l'host fisico, occupando improduttivamente
delle risorse fino al loro timeout. L'obiettivo della tesi è stato quello di
individuare questi job il più presto possibile, poiché identificarli nelle
loro fasi iniziali risulta essere particolarmente vantaggioso in termini di
risparmio di risorse derivante dalla loro rimozione. Dai risultati ottenuti
nel capitolo~\ref{chap:applicazione}, addestrando un apposito modello
predittivo, è possibile affermare che i job zombie sono identificabili. Sono
stati proposti e validati, su tutti i gruppi di utenti e con dati recenti
(vedi figura~\ref{table:model_results}), due modelli capaci di identificare i
job che, con buona probabilità, diventeranno zombie (1 su 2). Le predizioni
fornite dal modello possono essere utilizzate per impostare un filtro o un
avviso, permettendo così di controllare manualmente i job sospetti o di
stabilire una regola per la loro eliminazione.

\begin{table}[!ht]
    \centering
    \begin{tabular}{lcc}
        \toprule
        Metrica & Transformer & XGBoost \\ 
        \midrule
        Precisione (classe minoritaria) & 0.42 & 0.57 \\ 
        Recall (classe minoritaria) & 0.55 & 0.42 \\ 
        $F_1$ & 0.73 & 0.74 \\ 
        \bottomrule
    \end{tabular}
    \caption{\small Risultati dei modelli Transformer e XGBoost nell'identificazione
    dei job zombie sul set di test del dataset del periodo 13-31 marzo 2023}
    \label{table:model_results}
\end{table}

Il lavoro può essere proseguito per sviluppi futuri, partendo dai notebook
esistenti disponibili all'indirizzo
\url{https://github.com/alessioarcara/JobFailurePrediction-CNAF}.

Il passo successivo per una ricerca potenziale consiste nell'integrare,
anziché scegliere uno dei due classificatori, entrambi in un ensemble.
Combinando le previsioni di diversi classificatori e applicando una regola di
voto, è possibile compensare sorprendentemente le rispettive debolezze,
ottenendo prestazioni migliorate \cite{geron2019}. Si consiglia, dunque, di
esplorare ulteriori modelli e di integrarli in un ensemble.

Inoltre, l'incremento del numero di campionamenti da un'ora a 24 ore non ha
portato a un corrispondente incremento nella precisione. Tuttavia, questo
potrebbe essere dovuto al fatto di aver considerato più di un gruppo di
utenti. Un'altra ricerca potenziale che potrebbe migliorare le prestazioni è,
invece di considerare tutti i job di tutti i gruppi di utenti per addestrare
un unico modello, addestrare un modello per ogni gruppo di utenti. In questo
modo, si otterrebbe alla fine un array di modelli, che potrebbe mantenere le
stesse prestazioni osservate con il gruppo di utenti ATLAS.

Un altro aspetto importante è la qualità dei dati. Infatti, la qualità e la
quantità dei dati sono più importanti del modello utilizzato
\cite{halevy2009}. È utile arricchire le feature con dati provenienti da altre
fonti. Considerando che il CNAF monitora non solo lo stato dei job, ma anche
quello degli host fisici dove i job sono attualmente in esecuzione, con un
campionamento ogni 3 minuti, un'ulteriore direzione di ricerca potrebbe essere
quella di incrociare questi dati. In questo modo, si potrebbe ottenere
informazioni anche sull'ambiente in cui i job sono in esecuzione.

Sempre in merito ai dati, un'altra ricerca futura potrebbe concentrarsi sul
miglioramento della preparazione dei dati. Questo potrebbe includere
l'aggiunta di metodi alla classe \texttt{Preprocessor} per pulire le serie
storiche, ad esempio rimuovendo gli outlier o applicando una media mobile per
ridurre la variabilità. Inoltre, si potrebbero apportare miglioramenti anche
nell'etichettatura dei dati. Ad esempio, si potrebbe considerare come job
zombie non solo quelli che terminano a causa di un timeout di 7 giorni, ma
anche quelli in cui il \texttt{cputime} rimane invariato per un lungo periodo.
Ciò garantirebbe di identificare con maggiore sicurezza i job zombie, evitando
di classificare erroneamente quei job che richiedono più tempo per completare
i calcoli.
